### ğŸ“— çŸ­è¯­è¡¨ï¼ˆPhrasesï¼‰â€” arXiv:2601.14192

#### Efficiency & metricsï¼ˆæ•ˆç‡ä¸æŒ‡æ ‡ï¼‰

| è‹±æ–‡ | ç¾å¼éŸ³æ ‡ | ä¸­æ–‡å«ä¹‰ | è¿‘ä¹‰è¯ | ç¤ºä¾‹ |
|------|----------|----------|--------|------|
| cost-performance trade-off | /kÉ”Ëst pÉ™rËˆfÉ”ËrmÉ™ns ËˆtreÉªdËŒÉ”Ëf/ | æˆæœ¬-æ€§èƒ½æƒè¡¡ | costâ€“quality trade-off; efficiencyâ€“effectiveness trade-off | The paper frames efficiency as a cost-performance trade-off. |
| cost budget | /kÉ”Ëst ËˆbÊŒdÊ’Éªt/ | æˆæœ¬é¢„ç®—ï¼›èµ„æºä¸Šé™ | budget cap; spending limit | Compare effectiveness under a fixed cost budget. |
| token consumption | /ËˆtoÊŠkÉ™n kÉ™nËˆsÊŒmpÊƒÉ™n/ | token æ¶ˆè€— | token usage; token spend | Token consumption often dominates agent cost. |
| inference latency | /ËˆÉªnfÉ™rÉ™ns ËˆleÉªtÉ™nsi/ | æ¨ç†å»¶è¿Ÿ | serving latency; response time | Tool calls can increase inference latency dramatically. |
| computational cost | /ËŒkÉ‘ËmpjÉ™ËˆteÉªÊƒÉ™nÉ™l kÉ”Ëst/ | è®¡ç®—æˆæœ¬ | compute cost; processing cost | Efficiency aims to reduce computational cost without losing accuracy. |
| end-to-end latency | /ËŒÉ›nd tÉ™ ËˆÉ›nd ËˆleÉªtÉ™nsi/ | ç«¯åˆ°ç«¯å»¶è¿Ÿ | overall latency; total delay | Measure end-to-end latency including retrieval and tool time. |
| runtime cost | /ËˆrÊŒnËŒtaÉªm kÉ”Ëst/ | è¿è¡Œæ—¶æˆæœ¬ | runtime overhead; execution cost | Some benchmarks report runtime cost alongside accuracy. |
| step efficiency | /stÉ›p ÉªËˆfÉªÊƒÉ™nsi/ | æ­¥æ•°æ•ˆç‡ï¼ˆæ›´å°‘æ­¥éª¤è¾¾æˆç›®æ ‡ï¼‰ | step economy; trajectory efficiency | Memory can improve step efficiency by avoiding retries. |
| cost-of-pass | /kÉ”Ëst É™v pÃ¦s/ | æ¯æ¬¡æˆåŠŸçš„æœŸæœ›æˆæœ¬ | expected cost per success; economic success cost | Use cost-of-pass to link completion rate with cost. |
| Pareto frontier | /pÉ™ËˆreÉªtoÊŠ frÊŒnËˆtÉªr/ | å¸•ç´¯æ‰˜å‰æ²¿ | efficient frontier; trade-off curve | Methods lie on a Pareto frontier between cost and success. |

#### Agent formulation & loopï¼ˆå»ºæ¨¡ä¸å¾ªç¯ï¼‰

| è‹±æ–‡ | ç¾å¼éŸ³æ ‡ | ä¸­æ–‡å«ä¹‰ | è¿‘ä¹‰è¯ | ç¤ºä¾‹ |
|------|----------|----------|--------|------|
| planâ€“actâ€“observe loop | /plÃ¦n Ã¦kt É™bËˆzÉËv luËp/ | è®¡åˆ’-è¡ŒåŠ¨-è§‚å¯Ÿå¾ªç¯ | iterative loop; agent loop | Agents repeatedly run a planâ€“actâ€“observe loop to solve tasks. |
| memoryâ€“planningâ€“tool learning cycle | /ËˆmÉ›mÉ™ri ËˆplÃ¦nÉªÅ‹ tuËl ËˆlÉËnÉªÅ‹ ËˆsaÉªkÉ™l/ | è®°å¿†-è§„åˆ’-å·¥å…·å­¦ä¹ å¾ªç¯ | agent pipeline; interaction cycle | The survey decomposes cost sources by this cycle. |
| partially observable Markov decision process | /ËŒpÉ‘ËrÊƒÉ™li É™bËˆzÉËvÉ™bÉ™l ËˆmÉ‘ËrkÉ”Ëv dÉªËˆsÉªÊ’É™n ËˆproÊŠsÉ›s/ | éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆPOMDPï¼‰ | POMDP; stochastic control model | The agent is modeled as a POMDP with tools and memory. |
| transition kernel | /trÃ¦nËˆzÉªÊƒÉ™n ËˆkÉËnÉ™l/ | è½¬ç§»æ ¸ | transition function; dynamics kernel | The transition kernel defines environment dynamics. |
| reward function | /rÉªËˆwÉ”Ërd ËˆfÊŒÅ‹kÊƒÉ™n/ | å¥–åŠ±å‡½æ•° | payoff function; utility function | RL optimizes a reward function that can include cost terms. |
| discount factor | /ËˆdÉªskaÊŠnt ËˆfÃ¦ktÉ™r/ | æŠ˜æ‰£å› å­ | gamma; discount rate | The discount factor \(\gamma\) weighs future rewards. |
| tool interface | /tuËl ËˆÉªntÉ™rËŒfeÉªs/ | å·¥å…·æ¥å£ | API interface; tool API | A tool interface specifies how calls and outputs are handled. |
| memory update rule | /ËˆmÉ›mÉ™ri ËˆÊŒpËŒdeÉªt ruËl/ | è®°å¿†æ›´æ–°è§„åˆ™ | update policy; write rule | A memory update rule controls what to store and when. |

#### Memoryï¼ˆè®°å¿†ï¼šæ„å»º/ç®¡ç†/è®¿é—®ï¼‰

| è‹±æ–‡ | ç¾å¼éŸ³æ ‡ | ä¸­æ–‡å«ä¹‰ | è¿‘ä¹‰è¯ | ç¤ºä¾‹ |
|------|----------|----------|--------|------|
| working memory | /ËˆwÉËkÉªÅ‹ ËˆmÉ›mÉ™ri/ | å·¥ä½œè®°å¿†ï¼ˆæ¨ç†æ—¶å¯ç›´æ¥ä½¿ç”¨çš„ä¸Šä¸‹æ–‡/çŠ¶æ€ï¼‰ | short-term memory; active context | Working memory must stay compact to save tokens. |
| external memory | /ÉªkËˆstÉËnÉ™l ËˆmÉ›mÉ™ri/ | å¤–éƒ¨è®°å¿†ï¼ˆæ£€ç´¢å¼å­˜å‚¨ï¼‰ | long-term store; retrieval memory | External memory enables unbounded storage via retrieval. |
| memory construction | /ËˆmÉ›mÉ™ri kÉ™nËˆstrÊŒkÊƒÉ™n/ | è®°å¿†æ„å»º | memory formation; memory building | Memory construction often relies on summarization. |
| memory management | /ËˆmÉ›mÉ™ri ËˆmÃ¦nÉªdÊ’mÉ™nt/ | è®°å¿†ç®¡ç† | memory maintenance; memory curation | Memory management prevents storage explosion. |
| rule-based management | /ruËl beÉªst ËˆmÃ¦nÉªdÊ’mÉ™nt/ | åŸºäºè§„åˆ™çš„ç®¡ç† | heuristic management; policy-based control | Rule-based management is fast but can be brittle. |
| LLM-based management | /ËŒÉ›l ËŒÉ›l ËˆÉ›m beÉªst ËˆmÃ¦nÉªdÊ’mÉ™nt/ | åŸºäº LLM çš„ç®¡ç† | model-driven management; learned management | LLM-based management adds cost but is adaptive. |
| hybrid management | /ËˆhaÉªbrÉªd ËˆmÃ¦nÉªdÊ’mÉ™nt/ | æ··åˆå¼ç®¡ç† | combined strategy; mixed management | Hybrid management triggers LLM calls only when needed. |
| memory access | /ËˆmÉ›mÉ™ri ËˆÃ¦ksÉ›s/ | è®°å¿†è®¿é—® | recall; lookup | Memory access decides what to retrieve and how to use it. |
| memory selection | /ËˆmÉ›mÉ™ri sÉ™ËˆlÉ›kÊƒÉ™n/ | è®°å¿†é€‰æ‹© | retrieval selection; choosing memories | Memory selection balances relevance and latency. |
| memory integration | /ËˆmÉ›mÉ™ri ËŒÉªntÉ™ËˆÉ¡reÉªÊƒÉ™n/ | è®°å¿†æ•´åˆï¼ˆæ³¨å…¥æç¤º/èåˆä½¿ç”¨ï¼‰ | insertion; incorporation | Memory integration formats retrieved items into a compact block. |
| hierarchical memory | /ËŒhaÉªÉ™ËˆrÉ‘ËrkÉªkÉ™l ËˆmÉ›mÉ™ri/ | åˆ†å±‚è®°å¿† | tiered memory; multi-level memory | Hierarchical memory supports coarse-to-fine access. |
| graph-based memory | /ËˆÉ¡rÃ¦f beÉªst ËˆmÉ›mÉ™ri/ | å›¾ç»“æ„è®°å¿† | KG memory; graph store | Graph-based memory organizes entities and relations. |
| forgetting curve | /fÉ™rËˆÉ¡É›tÉªÅ‹ kÉËv/ | é—å¿˜æ›²çº¿ | decay curve; Ebbinghaus curve | A forgetting curve can decay stale memories over time. |
| FIFO replacement | /ËˆfaÉªfoÊŠ rÉªËˆpleÉªsmÉ™nt/ | å…ˆè¿›å…ˆå‡ºæ›¿æ¢ç­–ç•¥ | queue eviction; buffer eviction | FIFO replacement is a cheap rule for bounded buffers. |
| retrieval noise | /rÉªËˆtriËvÉ™l nÉ”Éªz/ | æ£€ç´¢å™ªå£° | irrelevant hits; retrieval errors | Retrieval noise can waste tokens and hurt accuracy. |
| vector similarity search | /ËˆvÉ›ktÉ™r ËŒsÉªmÉ™ËˆlÃ¦rÉªti sÉËtÊƒ/ | å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ | embedding search; semantic search | Vector similarity search retrieves top-k relevant memories. |

#### Tools & planningï¼ˆå·¥å…·å­¦ä¹ ä¸è§„åˆ’ï¼‰

| è‹±æ–‡ | ç¾å¼éŸ³æ ‡ | ä¸­æ–‡å«ä¹‰ | è¿‘ä¹‰è¯ | ç¤ºä¾‹ |
|------|----------|----------|--------|------|
| tool selection | /tuËl sÉ™ËˆlÉ›kÊƒÉ™n/ | å·¥å…·é€‰æ‹© | tool retrieval; tool picking | Tool selection avoids stuffing thousands of tools into the prompt. |
| tool calling | /tuËl ËˆkÉ”ËlÉªÅ‹/ | å·¥å…·è°ƒç”¨ | function calling; API calling | Tool calling adds extra latency beyond generation. |
| tool-integrated reasoning | /tuËl ËˆÉªntÉ™É¡reÉªtÉªd ËˆriËzÉ™nÉªÅ‹/ | å·¥å…·èåˆæ¨ç† | tool-augmented reasoning; TIR | Tool-integrated reasoning invokes tools only when necessary. |
| in-place parameter filling | /Éªn pleÉªs pÉ™ËˆrÃ¦mÉªtÉ™r ËˆfÉªlÉªÅ‹/ | åŸä½å‚æ•°å¡«å…… | inline parameterization; direct infilling | In-place parameter filling reduces extra formatting steps. |
| parallel tool calling | /ËˆpÃ¦rÉ™ËŒlÉ›l tuËl ËˆkÉ”ËlÉªÅ‹/ | å¹¶è¡Œå·¥å…·è°ƒç”¨ | concurrent calls; parallel execution | Parallel tool calling reduces wall-clock time for independent queries. |
| cost-aware tool calling | /ËˆkÉ”Ëst É™ËˆwÉ›r tuËl ËˆkÉ”ËlÉªÅ‹/ | æˆæœ¬æ„ŸçŸ¥çš„å·¥å…·è°ƒç”¨ | budget-aware calling; economical calling | Cost-aware tool calling trades extra calls for higher confidence. |
| tool-use penalty | /tuËl juËz ËˆpÉ›nÉ™lti/ | å·¥å…·ä½¿ç”¨æƒ©ç½šé¡¹ | call penalty; tool cost term | Add a tool-use penalty to discourage redundant calls. |
| efficiency-aware rewards | /ÉªËˆfÉªÊƒÉ™nsi É™ËˆwÉ›r rÉªËˆwÉ”Ërdz/ | æ•ˆç‡æ„ŸçŸ¥å¥–åŠ± | cost-sensitive rewards; parsimonious rewards | Efficiency-aware rewards optimize success per dollar. |
| budget-constrained tool learning | /ËˆbÊŒdÊ’Éªt kÉ™nËˆstreÉªnd tuËl ËˆlÉËnÉªÅ‹/ | é¢„ç®—çº¦æŸä¸‹çš„å·¥å…·å­¦ä¹  | budgeted tool use; constrained tooling | Budget-constrained tool learning plans calls under a hard cap. |
| fastâ€“slow thinking | /fÃ¦st sloÊŠ ËˆÎ¸ÉªÅ‹kÉªÅ‹/ | å¿«-æ…¢æ€è€ƒæœºåˆ¶ | dual-process; System 1/2 | Fastâ€“slow thinking allocates compute only when needed. |
| adaptive budgeting | /É™ËˆdÃ¦ptÉªv ËˆbÊŒdÊ’ÉªtÉªÅ‹/ | è‡ªé€‚åº”é¢„ç®—åˆ†é… | dynamic budgeting; compute allocation | Adaptive budgeting adjusts depth based on difficulty. |
| Monte Carlo tree search | /ËˆmÉ‘ËnteÉª ËˆkÉ‘ËrloÊŠ triË sÉËtÊƒ/ | è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ | MCTS; tree search | MCTS can guide exploration but adds overhead. |
| A* search | /ËˆeÉª stÉ‘Ër sÉËtÊƒ/ | A* æœç´¢ | heuristic search; best-first search | A* search prunes branches via a learned cost function. |
| task decomposition | /tÃ¦sk ËŒdiËkÉ™mËˆpoÊŠzÉªÊƒÉ™n/ | ä»»åŠ¡åˆ†è§£ | subtasking; breakdown | Task decomposition reduces step-by-step token redundancy. |
| protocol compression | /ËˆproÊŠtÌ¬É™ËŒkÉ”Ël kÉ™mËˆprÉ›ÊƒÉ™n/ | åè®®/äº¤æµå‹ç¼© | context compression; message compression | Protocol compression reduces communication tokens in multi-agent systems. |
| topology sparsification | /tÉ™ËˆpÉ‘ËlÉ™dÊ’i ËŒspÉ‘ËrsÉªfÉªËˆkeÉªÊƒÉ™n/ | æ‹“æ‰‘ç¨€ç–åŒ– | edge pruning; graph sparsification | Topology sparsification cuts quadratic communication overhead. |
