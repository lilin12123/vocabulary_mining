### ğŸ“˜ è¯æ±‡è¡¨ï¼ˆWordsï¼‰

| è‹±æ–‡ | ç¾å¼éŸ³æ ‡ | ä¸­æ–‡å«ä¹‰ | ç¤ºä¾‹ |
|------|----------|--------|------|
| pretraining | /ËŒpriËËˆtreÉªnÉªÅ‹/ | é¢„è®­ç»ƒ | LLMs acquire general knowledge during pretraining. |
| fine-tuning | /ËŒfaÉªnËˆtuËnÉªÅ‹/ | å¾®è°ƒ | Supervised fine-tuning enhances instruction-following ability. |
| curate | /kjÊŠËˆreÉªt/ | ç²¾å¿ƒç­›é€‰ã€ç­–å±• | Researchers curate high-quality instruction datasets. |
| curation | /kjÊŠËˆreÉªÊƒn/ | ç­›é€‰è¿‡ç¨‹ã€ç­–å±•è¡Œä¸º | Data curation is vital for effective SFT. |
| heterogeneous | /ËŒhetÉ™rÉ™ËˆdÊ’iËniÉ™s/ | å¼‚æ„çš„ã€å¤šæ ·åŒ–çš„ | Heterogeneous dataset composition improves model robustness. |
| homogeneous | /ËŒhoÊŠmÉ™ËˆdÊ’iËniÉ™s/ | åŒè´¨çš„ | Homogeneous data may limit generalization. |
| deduplication | /diËËŒdjuËplÉªËˆkeÉªÊƒn/ | å»é‡ | Deduplication mitigates memorization risks. |
| toxicity | /tÉ‘ËkËˆsÉªsÉ™ti/ | æœ‰å®³æ€§ï¼ˆæ–‡æœ¬ï¼‰ | Toxicity filtering reduces offensive outputs. |
| detoxify | /diËËˆtÉ‘ËksÉªfaÉª/ | å»æ¯’åŒ– | Detoxifying training data improves safety. |
| debias | /diËËˆbeÉªÉ™s/ | å»åè§ | We must debias datasets to ensure fairness. |
| bias | /ËˆbaÉªÉ™s/ | åè§ | Social bias in corpora affects model behavior. |
| mitigate | /ËˆmÉªtÉªÉ¡eÉªt/ | ç¼“è§£ | Techniques mitigate negative task interference. |
| evoke | /ÉªËˆvoÊŠk/ | æ¿€å‘ | SFT evokes instruction-following abilities. |
| synthesis | /ËˆsÉªnÎ¸É™sÉªs/ | åˆæˆï¼ˆè¿‡ç¨‹ï¼‰ | Data synthesis addresses scarcity issues. |
| heuristic | /hjuËËˆrÉªstÉªk/ | å¯å‘å¼çš„ï¼›ç»éªŒæ³•åˆ™ | Heuristic filters remove low-quality text. |
| perplexity | /pÉ™rËˆpleksÉ™ti/ | å›°æƒ‘åº¦ | Lower perplexity often indicates higher fluency. |
| memorization | /ËŒmemÉ™rÉ™ËˆzeÉªÊƒn/ | è®°å¿†ï¼ˆè¿‡æ‹Ÿåˆï¼‰ | Deduplication reduces unwanted memorization. |
| generalization | /ËŒdÊ’enÉ™rÉ™lÉ™ËˆzeÉªÊƒn/ | æ³›åŒ–èƒ½åŠ› | Over-filtering harms generalization. |
| alignment | /É™ËˆlaÉªnmÉ™nt/ | å¯¹é½ï¼ˆäººç±»æ„å›¾ï¼‰ | SFT improves alignment with human expectations. |
| instruction-following | /ÉªnËˆstrÊŒkÊƒn ËˆfÉ‘ËloÊŠÉªÅ‹/ | éµå¾ªæŒ‡ä»¤èƒ½åŠ› | This ability is critical for chatbots. |
| emergent | /ÉªËˆmÉœËrdÊ’É™nt/ | æ¶Œç°çš„ | LLMs show emergent reasoning skills. |
| scalable | /ËˆskeÉªlÉ™bl/ | å¯æ‰©å±•çš„ | The pipeline must be scalable to trillion-token data. |
| degradation | /ËŒdeÉ¡rÉ™ËˆdeÉªÊƒn/ | æ€§èƒ½ä¸‹é™ | Multi-epoch training causes degradation. |
| regularization | /ËŒreÉ¡jÉ™lÉ™rÉ™ËˆzeÉªÊƒn/ | æ­£åˆ™åŒ– | Dropout is a form of regularization. |
| robustness | /roÊŠËˆbÊŒstnÉ™s/ | é²æ£’æ€§ | Diversity improves model robustness. |
| coarse-grained | /ËŒkoÊŠrsËˆÉ¡reÉªnd/ | ç²—ç²’åº¦çš„ | C-RLFT uses coarse-grained reward labels. |
| fine-grained | /ËŒfaÉªnËˆÉ¡reÉªnd/ | ç»†ç²’åº¦çš„ | Fine-grained data ordering boosts performance. |
| semantic | /sÉªËˆmÃ¦ntÉªk/ | è¯­ä¹‰çš„ | Semantic deduplication removes near-duplicates. |
| grammatical | /É¡rÉ™ËˆmÃ¦tÉªkl/ | è¯­æ³•çš„ï¼Œå’Œè¯­æ³•æœ‰å…³çš„ | Native speakers can distinguish between grammatical and ungrammatical sentences even when they have never heard particular combinations before. |
| latent | /ËˆleÉªtnt/ | æ½œåœ¨çš„ | Latent conflicts exist among tasks. |
| interference | /ËŒÉªntÉ™rËˆfÉªrÉ™ns/ | å¹²æ‰° | Negative interference occurs in multitask SFT. |
| autonomous | /É”ËËˆtÉ‘ËnÉ™mÉ™s/ | è‡ªä¸»çš„ | Future systems should be autonomous. |
| exhaustion | /ÉªÉ¡ËˆzÉ”ËstÊƒn/ | è€—å°½ | Concerns about data exhaustion are rising. |
| iteratively | /ËˆÉªtÉ™rÉ™tÉªvli/ | è¿­ä»£åœ° | Self-feedback improves responses iteratively. |
| progressively | /prÉ™ËˆÉ¡resÉªvli/ | é€æ­¥åœ° | Learn progressively from easy to hard. |
| log-linear | /ËŒlÉ”ËÉ¡ ËˆlÉªniÉ™r/ | å¯¹æ•°çº¿æ€§çš„ | A log-linear relation exists for math tasks. |
| multiplicative | /ËŒmÊŒltÉªËˆplÉªkÉ™tÉªv/ | ä¹˜æ€§çš„ | Power-based multiplicative scaling law. |
| taxonomy | /tÃ¦kËˆsÉ‘ËnÉ™mi/ | åˆ†ç±»ä½“ç³» | Figure 3 shows the full taxonomy. |
| synthetic | /sÉªnËˆÎ¸É›tÉªk/ | åˆæˆçš„ï¼›äººå·¥ç”Ÿæˆçš„ | Synthetic data can mimic real-world distributions. |
| augmentation | /ËŒÉ”ËÉ¡mÉ›nËˆteÉªÊƒn/ | å¢å¼ºï¼›æ‰©å…… | Data augmentation improves model robustness. |
| fidelity | /fÉªËˆdÉ›lÉ™ti/ | ä¿çœŸåº¦ï¼›å¿ å®åº¦ | Ensuring high fidelity in generated text is critical. |
| realism | /ËˆriËÉ™ËŒlÉªzÉ™m/ | çœŸå®æ„Ÿï¼›ç°å®æ€§ | The realism of synthetic code affects downstream performance. |
| hallucination | /hÉ™ËŒluËsÉªËˆneÉªÊƒn/ | å¹»è§‰ï¼ˆæ¨¡å‹ç”Ÿæˆè™šå‡å†…å®¹ï¼‰ | LLMs are prone to hallucination when generating facts. |
| grounded | /ËˆÉ¡raÊŠndÉªd/ | æœ‰ä¾æ®çš„ï¼›åŸºäºäº‹å®çš„ | Retrieval-augmented generation produces more grounded outputs. |
| factuality | /fÃ¦kËˆtÊƒuËÃ¦lÉ™ti/ | äº‹å®å‡†ç¡®æ€§ | Evaluating factuality remains a key challenge in synthetic QA. |
| veracity | /vÉ™ËˆrÃ¦sÉ™ti/ | çœŸå®æ€§ï¼›å‡†ç¡®æ€§ | The veracity of synthetic clinical notes must be verified. |
| iterative | /ËˆÉªtÉ™rÉ™tÉªv/ | è¿­ä»£çš„ | Iterative self-refinement improves dataset coherence. |
| refinement | /rÉªËˆfaÉªnmÉ™nt/ | ç²¾ç‚¼ï¼›ä¼˜åŒ– | Prompt refinement leads to higher-quality examples. |
| bootstrapping | /ËˆbuËtËŒstrÃ¦pÉªÅ‹/ | è‡ªä¸¾ï¼›è‡ªå¼•å¯¼ | Self-Instruct uses bootstrapping to generate instructions. |
| scalability | /ËŒskeÉªlÉ™ËˆbÉªlÉ™ti/ | å¯æ‰©å±•æ€§ | Synthetic data offers near-unlimited scalability. |
| controllability | /kÉ™nËŒtroÊŠlÉ™ËˆbÉªlÉ™ti/ | å¯æ§æ€§ | Controllability allows targeting rare phenomena. |
| diversity | /daÉªËˆvÉœËrsÉ™ti/ | å¤šæ ·æ€§ | Diversity in prompts reduces output redundancy. |
| distributional | /ËŒdÉªstrÉªËˆbjuËÊƒÉ™nl/ | åˆ†å¸ƒç›¸å…³çš„ | Distributional alignment prevents model drift. |
| mitigation | /ËŒmÉªtÉªËˆÉ¡eÉªÊƒn/ | ç¼“è§£ï¼›å‡è½» | Filtering is a common mitigation strategy. |
| monolingual | /ËŒmÉ‘ËnÉ™ËˆlÉªÅ‹É¡wÉ™l/ | å•è¯­çš„ï¼›ä»…ç”¨ä¸€ç§è¯­è¨€çš„ | Not all Americans are monolingual of course. |
| compiler | /kÉ™mËˆpaÉªlÉ™r/ | ç¼–è¯‘å™¨ | Compilers detect syntax errors in generated code. |
| transpiler | /trÃ¦nsËˆpaÉªlÉ™r/ | è½¬è¯‘å™¨ | LLMs generate parallel data for transpiler training. |
| refactoring | /ËŒriËËˆfÃ¦ktÉ™rÉªÅ‹/ | é‡æ„ | Refactoring creates stylistically diverse but equivalent code. |
| downstream | /ËŒdaÊŠnËˆstriËm/ | ä¸‹æ¸¸çš„ | Downstream task performance validates synthetic utility. |
| overfitting | /ËŒoÊŠvÉ™rËˆfÉªtÉªÅ‹/ | è¿‡æ‹Ÿåˆ | Overfitting to synthetic patterns harms real-world performance. |
| adversarial | /ËŒÃ¦dvÉ™rËˆsÉ›riÉ™l/ | å¯¹æŠ—æ€§çš„ | Adversarial filtering improves realism. |
| faithfulness | /ËˆfeÉªÎ¸fÉ™lnÉ™s/ | å¿ å®åº¦ï¼ˆå†…å®¹ä¸äº‹å®ä¸€è‡´ï¼‰ | Faithfulness metrics assess hallucination risk. |
| coherence | /koÊŠËˆhirÉ™ns/ | è¿è´¯æ€§ | Generated dialogues must maintain multi-turn coherence. |
| nuanced | /ËˆnuËÉ‘Ënst/ | ç»†å¾®å·®åˆ«çš„ï¼›ç»†è‡´çš„ | Larger models produce more nuanced outputs. |
| idiosyncrasy | /ËŒÉªdiÉ™ËˆsÉªÅ‹krÉ™si/ | ç‰¹æ®Šä¹ æ€§ï¼›ç‹¬ç‰¹æ€§ | Real data contains idiosyncrasies absent in synthetic text. |
| anonymization | /É™ËŒnÉ‘ËnÉªmÉ™ËˆzeÉªÊƒn/ | åŒ¿ååŒ– | Synthetic data enables privacy-preserving anonymization. |
| regurgitation | /rÉªËŒÉ¡ÉœËrdÊ’ÉªËˆteÉªÊƒn/ | ï¼ˆæœºæ¢°ï¼‰å¤è¿° | Avoid regurgitation of copyrighted training data. |
| validation | /ËŒvÃ¦lÉªËˆdeÉªÊƒn/ | éªŒè¯ | Human validation complements automated checks. |
| benchmark | /ËˆbÉ›ntÊƒmÉ‘Ërk/ | åŸºå‡†æµ‹è¯• | HumanEval is a standard benchmark for code generation. |

